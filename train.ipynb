{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_video\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive mounted\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"Drive mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "num_classes = 11 # crowd11 classes for movement\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "file_path = '/content/drive/MyDrive/CABR/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict_motion = {\n",
    "    0: 'gas_free',\n",
    "    1: 'gas_jammed',\n",
    "    2: 'laminar_flow',\n",
    "    3: 'turbulent_flow',\n",
    "    4: 'crossing_flow',\n",
    "    5: 'merging_flow',\n",
    "    6: 'diverging_flow',\n",
    "    7: 'static_calm',\n",
    "    8: 'static_agitated',\n",
    "    9: 'interacting_crowd',\n",
    "    10: 'no_crowd'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppearanceBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AppearanceBranch, self).__init__()\n",
    "        \n",
    "        self.branch_appearance = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LocalResponseNorm(size=5),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LocalResponseNorm(size=5),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_appearance = self.branch_appearance(x)\n",
    "        return out_appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MotionBranch, self).__init__()\n",
    "        \n",
    "        self.branch_motion = nn.Sequential(\n",
    "            nn.Conv2d(20, 96, kernel_size=7, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LocalResponseNorm(size=5),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LocalResponseNorm(size=5),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_motion = self.branch_motion(x)\n",
    "        return out_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeeplyLearnedAttributes(\n",
      "  (appearance_branch): AppearanceBranch(\n",
      "    (branch_appearance): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "      (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(2, 2))\n",
      "      (5): ReLU()\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "      (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (13): ReLU()\n",
      "      (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (15): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (motion_branch): MotionBranch(\n",
      "    (branch_motion): Sequential(\n",
      "      (0): Conv2d(20, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "      (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(2, 2))\n",
      "      (5): ReLU()\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "      (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (13): ReLU()\n",
      "      (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (15): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (concat): Linear(in_features=8192, out_features=51, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DeeplyLearnedAttributes(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeeplyLearnedAttributes, self).__init__()\n",
    "        \n",
    "        self.appearance_branch = AppearanceBranch()\n",
    "        self.motion_branch = MotionBranch()\n",
    "        self.concat = nn.Linear(4096*2, 51)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x_appearance, x_motion):\n",
    "        out_appearance = self.appearance_branch(x_appearance)\n",
    "        out_motion = self.motion_branch(x_motion)\n",
    "        out = torch.cat((out_appearance, out_motion), dim=1)\n",
    "        out = self.concat(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = DeeplyLearnedAttributes()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D(nn.Module):\n",
    "    def __init__(self, num_classes=487):\n",
    "        super(C3D, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=3, padding=1)\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3a(x))\n",
    "        x = F.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.conv4a(x))\n",
    "        x = F.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = F.relu(self.conv5a(x))\n",
    "        x = F.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3a): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv3b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4a): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv4b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5a): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv5b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc6): Linear(in_features=8192, out_features=4096, bias=True)\n",
       "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc8): Linear(in_features=4096, out_features=487, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model(input_shape=(3, 16, 112, 112), summary=False, num_classes=487):\n",
    "    model = C3D(num_classes=num_classes)\n",
    "    if summary:\n",
    "        print(model)\n",
    "    return model\n",
    "\n",
    "get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking appearance and motion branch\n",
    "\n",
    "class DeeplyLearnedAttributesModified(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeeplyLearnedAttributesModified, self).__init__()\n",
    "        \n",
    "        self.appearance_branch = AppearanceBranch()\n",
    "        self.motion_branch = C3D()\n",
    "        self.concat = nn.Linear(4096*2, 51)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x_appearance, x_motion):\n",
    "        out_appearance = self.appearance_branch(x_appearance)\n",
    "        out_motion = self.motion_branch(x_motion)\n",
    "        out = torch.cat((out_appearance, out_motion), dim=1)\n",
    "        out = self.concat(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeeplyLearnedAttributesModified(\n",
      "  (appearance_branch): AppearanceBranch(\n",
      "    (branch_appearance): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "      (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(2, 2))\n",
      "      (5): ReLU()\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "      (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (13): ReLU()\n",
      "      (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (15): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (motion_branch): C3D(\n",
      "    (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3a): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (conv3b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv4a): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (conv4b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv5a): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (conv5b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (fc6): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "    (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (fc8): Linear(in_features=4096, out_features=487, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (concat): Linear(in_features=8192, out_features=51, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_model_obj = DeeplyLearnedAttributesModified()\n",
    "print(new_model_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionMapsDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.file_paths[idx]\n",
    "        frames, frame_rate = read_video(video_path)\n",
    "        if self.transform:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "        frames = torch.stack(frames)\n",
    "        label = self._extract_label(video_path)\n",
    "        return frames, label\n",
    "\n",
    "    def _extract_label(self, video_path):\n",
    "        return int(video_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = MotionMapsDataset(file_paths=file_path, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters(), lr=0.001)odel = C3D().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "Epoch [2/100]\n",
      "Epoch [3/100]\n",
      "Epoch [4/100]\n",
      "Epoch [5/100]\n",
      "Epoch [6/100]\n",
      "Epoch [7/100]\n",
      "Epoch [8/100]\n",
      "Epoch [9/100]\n",
      "Epoch [10/100]\n",
      "Epoch [11/100]\n",
      "Epoch [12/100]\n",
      "Epoch [13/100]\n",
      "Epoch [14/100]\n",
      "Epoch [15/100]\n",
      "Epoch [16/100]\n",
      "Epoch [17/100]\n",
      "Epoch [18/100]\n",
      "Epoch [19/100]\n",
      "Epoch [20/100]\n",
      "Epoch [21/100]\n",
      "Epoch [22/100]\n",
      "Epoch [23/100]\n",
      "Epoch [24/100]\n",
      "Epoch [25/100]\n",
      "Epoch [26/100]\n",
      "Epoch [27/100]\n",
      "Epoch [28/100]\n",
      "Epoch [29/100]\n",
      "Epoch [30/100]\n",
      "Epoch [31/100]\n",
      "Epoch [32/100]\n",
      "Epoch [33/100]\n",
      "Epoch [34/100]\n",
      "Epoch [35/100]\n",
      "Epoch [36/100]\n",
      "Epoch [37/100]\n",
      "Epoch [38/100]\n",
      "Epoch [39/100]\n",
      "Epoch [40/100]\n",
      "Epoch [41/100]\n",
      "Epoch [42/100]\n",
      "Epoch [43/100]\n",
      "Epoch [44/100]\n",
      "Epoch [45/100]\n",
      "Epoch [46/100]\n",
      "Epoch [47/100]\n",
      "Epoch [48/100]\n",
      "Epoch [49/100]\n",
      "Epoch [50/100]\n",
      "Epoch [51/100]\n",
      "Epoch [52/100]\n",
      "Epoch [53/100]\n",
      "Epoch [54/100]\n",
      "Epoch [55/100]\n",
      "Epoch [56/100]\n",
      "Epoch [57/100]\n",
      "Epoch [58/100]\n",
      "Epoch [59/100]\n",
      "Epoch [60/100]\n",
      "Epoch [61/100]\n",
      "Epoch [62/100]\n",
      "Epoch [63/100]\n",
      "Epoch [64/100]\n",
      "Epoch [65/100]\n",
      "Epoch [66/100]\n",
      "Epoch [67/100]\n",
      "Epoch [68/100]\n",
      "Epoch [69/100]\n",
      "Epoch [70/100]\n",
      "Epoch [71/100]\n",
      "Epoch [72/100]\n",
      "Epoch [73/100]\n",
      "Epoch [74/100]\n",
      "Epoch [75/100]\n",
      "Epoch [76/100]\n",
      "Epoch [77/100]\n",
      "Epoch [78/100]\n",
      "Epoch [79/100]\n",
      "Epoch [80/100]\n",
      "Epoch [81/100]\n",
      "Epoch [82/100]\n",
      "Epoch [83/100]\n",
      "Epoch [84/100]\n",
      "Epoch [85/100]\n",
      "Epoch [86/100]\n",
      "Epoch [87/100]\n",
      "Epoch [88/100]\n",
      "Epoch [89/100]\n",
      "Epoch [90/100]\n",
      "Epoch [91/100]\n",
      "Epoch [92/100]\n",
      "Epoch [93/100]\n",
      "Epoch [94/100]\n",
      "Epoch [95/100]\n",
      "Epoch [96/100]\n",
      "Epoch [97/100]\n",
      "Epoch [98/100]\n",
      "Epoch [99/100]\n",
      "Epoch [100/100]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_accuracy = correct_predictions / total_samples * 100.0\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '000125733.npy'\n",
    "inference_data = file_path + 'test/' + test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2, Predicted Class Label: laminar_flow\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "video_path = inference_data\n",
    "frame = MotionMapsDataset(file_paths=video_path, transform=transform)\n",
    "frames = DataLoader(frame, batch_size=1, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(frames.unsqueeze(0))\n",
    "\n",
    "probabilities = torch.softmax(outputs, dim=1)\n",
    "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}, Predicted Class Label: {class_dict_motion[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '055271257.npy'\n",
    "inference_data = file_path + 'test/' + test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2, Predicted Class Label: laminar_flow\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "video_path = inference_data\n",
    "frame = MotionMapsDataset(file_paths=video_path, transform=transform)\n",
    "frames = DataLoader(frame, batch_size=1, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(frames.unsqueeze(0))\n",
    "\n",
    "probabilities = torch.softmax(outputs, dim=1)\n",
    "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}, Predicted Class Label: {class_dict_motion[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
